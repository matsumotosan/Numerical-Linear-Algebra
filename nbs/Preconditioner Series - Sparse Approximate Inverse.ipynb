{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preconditioner Series: Sparse Approximate Inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The premise of sparse approximate inverse (SAI) preconditioners is to explicitly calculate a sparse approximation of $A^{-1}$ such that $M\\approx A^{-1}$.\n",
    "\n",
    "Below, I implement the following SAI methods with the help of PyTorch:\n",
    "1. Frobenius norm minimization\n",
    "    1. SPAI algorithm\n",
    "    2. MR algorithm\n",
    "    3. Self-preconditioned MR algorithm\n",
    "2. Factorized sparse approximate inverses\n",
    "    1. Biconjugation algorithm\n",
    "3. Inverse ILU techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# import torch.cuda as tc\n",
    "from torch.autograd import Variable\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparsity(M):\n",
    "    return 1 - np.count_nonzero(M.numpy()) / torch.numel(M)\n",
    "\n",
    "def report(A, M):\n",
    "    print((torch.eye(n) - torch.mm(A, M)).norm(2).item(), sparsity(M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frobenius norm minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This class of methods is based on the computation of a sparse matrix $M=A^{-1}$ from the following constrained minimization problem:\n",
    "\n",
    "$$ \\min_{M\\in S} \\lVert I-AM\\rVert_F$$\n",
    "\n",
    "where $S$ is a set of sparse matrices. The above problem can be solved for a right approximate inverse. The left approxiate inverse can be calculated by minimizing $\\lVert I-MA\\rVert_F$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAI algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most successful algorithms proposed in this class is known as the SPAI preconditioner. The algorithm is described [here](https://arxiv.org/abs/1503.04500) and [here](http://www.mathcs.emory.edu/~benzi/Web_papers/comp.pdf) and is as follows:\n",
    "\n",
    "For every column $m_j$ of $M$:\n",
    "\n",
    "1. Choose an initial sparsity pattern $J$\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spai(A):\n",
    "    \n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MR algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [MR algorithm](https://www.cc.gatech.edu/~echow/pubs/newapinv.pdf)\n",
    "\n",
    "For an n-by-n matrix $A$:\n",
    "\n",
    "1. Choose an initial guess $M=M_0=[m_1, m_2,\\dots,m_n]$\n",
    "2. For each column $m_j$, $j=1,2,\\dots,n$\n",
    "    1. For $i$ in $1,2,\\dots,n_i$\n",
    "        1. $r_j=e_j-Am_j$\n",
    "        2. $\\alpha_j=r_j^TAr_j/((Ar_j)^T(Ar_j))$\n",
    "        3. $m_j=m_j+\\alpha_jr_j$\n",
    "        4. Numerical dropping on $m_j$\n",
    "        \n",
    "**Numerical dropping?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-94-b9c1c93cfe2e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-94-b9c1c93cfe2e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def mr(A, M0, ni, tol):\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def drop(m):\n",
    "    \n",
    "\n",
    "def mr(A, M, ni=10, tol=1e-3):\n",
    "    n = A.shape[0]\n",
    "    e = np.eye(n)\n",
    "    \n",
    "    for j in range(n):\n",
    "        for i in range(ni):\n",
    "            r = e[j] - A @ M[:,j]\n",
    "            a = r.T @ A @ r / ((A @ r).T @ (A @ r))\n",
    "            M[:,j] += a * r\n",
    "            drop(M[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "A = np.random.rand(n, n)\n",
    "M0 = np.eye(n)\n",
    "\n",
    "# mr(A, M0)\n",
    "M0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-preconditioned MR algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_mr(A, M0, ni, tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorized sparse approximate inverses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biconjugation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse ILU techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plain old L1-regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having learned about L1-regularization in machine learning, I wondered how such a simple method would do when calculating a sparse approximate inverse.\n",
    "\n",
    "The minimization problem here is:\n",
    "\n",
    "$$ \\min_{M} \\lVert I-AM\\rVert_F + \\alpha\\lVert M\\rVert_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(A, M, n, alpha):\n",
    "    return torch.norm(torch.mm(A, M) - torch.eye(n), p='fro') + alpha * torch.norm(M ,p=1)\n",
    "\n",
    "def plain_l1(A, lr=1e-3, alpha=1e5, eps=1e-3, rtol=1e-5, max_iter=10000):\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    pA = Variable(torch.FloatTensor(A), requires_grad=False)\n",
    "    pM = Variable(torch.randn(n, n), requires_grad=True)\n",
    "    \n",
    "    opt = torch.optim.SGD([pM], lr)\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        opt.zero_grad()\n",
    "        pA[torch.abs(pA) < eps] = 0\n",
    "        l = loss(pA, pM, n, alpha)\n",
    "        l.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        if i % 1000 == 999:\n",
    "            report(pA.data, pM.data)\n",
    "    \n",
    "    return pM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.953068733215332 0.0\n",
      "3.1871531009674072 0.0\n",
      "3.158658027648926 0.0\n",
      "3.159771680831909 0.0\n",
      "3.1595215797424316 0.0\n",
      "3.159792900085449 0.0\n",
      "3.1589648723602295 0.0\n",
      "3.160285472869873 0.0\n",
      "3.159102201461792 0.0\n",
      "3.1588714122772217 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00045629, -0.00012942, -0.0002652 ,  0.00078636,  0.00121963,\n",
       "         0.00010997,  0.00093774,  0.00093873, -0.00032723,  0.00013044],\n",
       "       [ 0.00005528,  0.00081641,  0.00032489,  0.00007263,  0.00080921,\n",
       "        -0.00013259, -0.00047741, -0.00032341,  0.00071864,  0.00011489],\n",
       "       [ 0.00059126,  0.00071992, -0.00067428, -0.00064733,  0.00070266,\n",
       "        -0.00001875,  0.00068053, -0.00034219,  0.00083424, -0.0003781 ],\n",
       "       [ 0.00065093,  0.00109324, -0.00061818,  0.00081611, -0.00016427,\n",
       "         0.00051789,  0.0004282 , -0.00017426, -0.00082078,  0.00005166],\n",
       "       [ 0.00020285, -0.00079511, -0.00095196,  0.00124755,  0.00062162,\n",
       "         0.00095477, -0.00011105,  0.00047384, -0.00035185, -0.00055214],\n",
       "       [-0.00029456,  0.00030927,  0.00089606, -0.0008059 , -0.00013875,\n",
       "         0.0011206 ,  0.00026234,  0.00013471,  0.00089078,  0.00085093],\n",
       "       [-0.00022143,  0.00032813,  0.00033733,  0.00001479,  0.00075345,\n",
       "         0.00014675,  0.00091832,  0.00000916, -0.00032844,  0.00063702],\n",
       "       [ 0.00032789,  0.00028031,  0.00083826, -0.00008363,  0.00001712,\n",
       "        -0.00013435,  0.00089123,  0.00073889,  0.00086254, -0.00071151],\n",
       "       [-0.00023262,  0.00078461, -0.0007725 ,  0.00075133,  0.00027973,\n",
       "         0.00085408,  0.00002127,  0.00009487, -0.00011115, -0.00029059],\n",
       "       [-0.00086558,  0.00052524, -0.00037528, -0.00089637,  0.00004779,\n",
       "         0.00091589, -0.0001557 , -0.00028787, -0.00048042, -0.00071345]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10\n",
    "A = np.random.rand(n, n)\n",
    "M = plain_l1(A, lr=1e-3, alpha=1, eps=1e-3)\n",
    "\n",
    "M.data.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A comparative study of sparse approximate inverse preconditioners](http://www.mathcs.emory.edu/~benzi/Web_papers/comp.pdf)\n",
    "\n",
    "[A Residual Based Sparse Approximate Inverse Preconditioning Procedure for Large Sparse Linear Systems](https://arxiv.org/abs/1503.04500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
